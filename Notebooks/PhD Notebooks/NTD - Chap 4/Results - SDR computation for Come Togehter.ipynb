{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:11.555175Z",
     "start_time": "2022-08-01T11:16:03.553248Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "import barmuscomp.scripts.overall_scripts as scr\n",
    "import barmuscomp.model.pattern_study as ps\n",
    "import barmuscomp.model.features as features\n",
    "import as_seg.data_manipulation as dm\n",
    "from barmuscomp.model.current_plot import *\n",
    "import barmuscomp.scripts.default_path as paths\n",
    "import as_seg.barwise_input as bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:11.821460Z",
     "start_time": "2022-08-01T11:16:11.561159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Song\n",
    "song_path = \"C:/Users/amarmore/this_folder/The Beatles - Come Together.wav\"\n",
    "the_signal, sasmpling_rate = sf.read(song_path)\n",
    "song_name = \"The Beatles - Come Together\"\n",
    "\n",
    "bars = np.load(\"C:/Users/amarmore/Desktop/data_persisted/bars/The Beatles - Come Together.npy\") #dm.get_bars_from_audio(song_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFT\n",
    "Let's compute the STFT of the song:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:11.851378Z",
     "start_time": "2022-08-01T11:16:11.830438Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fft=2048\n",
    "hop_length = 32\n",
    "\n",
    "#stft_complex = librosa.core.stft(np.asfortranarray(the_signal[:,0]), n_fft=n_fft, hop_length = hop_length)\n",
    "#if the_signal.shape[1] > 1:\n",
    "#    for i in range(1,the_signal.shape[1]):\n",
    "#        stft_complex += librosa.core.stft(np.asfortranarray(the_signal[:,i]), n_fft=n_fft, hop_length = hop_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then form the Time-Frequency-Bar tensor $\\mathscr{X}$ of this STFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:12.115187Z",
     "start_time": "2022-08-01T11:16:11.859358Z"
    }
   },
   "outputs": [],
   "source": [
    "hop_length_seconds = hop_length / 44100\n",
    "subdivision = 96\n",
    "\n",
    "#complex_tensor_stft = bi.tensorize_barwise_FTB(stft_complex, bars, hop_length_seconds, subdivision)\n",
    "#tensor_mag, tensor_phase = librosa.magphase(complex_tensor_stft, power=1) \n",
    "\n",
    "tensor_mag = np.load(\"C:/Users/amarmore/Desktop/data_persisted/cometogether/tensor_mag_ntd.npy\", allow_pickle = True)\n",
    "tensor_phase = np.load(\"C:/Users/amarmore/Desktop/data_persisted/cometogether/tensor_phase_ntd.npy\", allow_pickle = True)\n",
    "\n",
    "nb_bars_song = tensor_mag.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline, we reconstruct the song from the unfolded tensor spectrogram. Hence, the song will be reconstructed from the 96 chosen samples per bar (subdivision parameter which defines the number of samples per bar, subsampling the previous over-sampled STFT).\n",
    "\n",
    "To reconstruct the audio signal, Inverse STFT needs the hop length of the STFT. As bars can be of different length, and we subsampled 96 samples per bar, we compute the median hop length from the different bars, and applies it to all bars in our song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:12.146103Z",
     "start_time": "2022-08-01T11:16:12.126158Z"
    }
   },
   "outputs": [],
   "source": [
    "median_hop = ps.get_median_hop(bars, subdivision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's recreate the signal from the barwise STFT, in order to study the reconstruction quality of the Inverse STFT algorithm, and have a listenable baseline. We limit the song to a certain number of bars (not to overload the final HTML file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:12.161066Z",
     "start_time": "2022-08-01T11:16:12.157074Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nb_bars_to_plot = 16 # you can set it to 89 if you use the executable format, and listen to the whole song.\n",
    "#signal_stft_istft = librosa.istft(np.reshape((tensor_mag*tensor_phase)[:,:,:nb_bars], (1025, nb_bars_to_plot * subdivision), order = 'F'), hop_length = median_hop)\n",
    "#ipd.Audio(signal_stft_istft, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already hear some small artifacts from the reconstruction. Hence, reconstructed signals won't be better than this one, which is already disturbed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTD: Nonnegative Tucker Decomposition\n",
    "Let's compute the NTD of this TFB tensor, and study the reconstructed signal and the barwise patterns obtained in the decomposition.\n",
    "\n",
    "As a recall, NTD is a tensor decomposition method, which can be used to retrieve patterns from data.\n",
    "\n",
    "<img src=\"imgs/NTD.png\" width=\"500\"/>\n",
    "\n",
    "We refer to [1,2] for details.\n",
    "\n",
    "First, we need to set the dimensions of the decomposition, corresponding to the core dimensions. They are set empirically here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:12.207772Z",
     "start_time": "2022-08-01T11:16:12.186997Z"
    }
   },
   "outputs": [],
   "source": [
    "ntd_dimensions = [32,12,10] #Dimensions of the decomposition\n",
    "init_ntd = \"tucker\"\n",
    "\n",
    "listen_audio = False\n",
    "plot_patterns = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BETA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:16:12.239208Z",
     "start_time": "2022-08-01T11:16:12.214261Z"
    }
   },
   "outputs": [],
   "source": [
    "persisted_arguments = f\"_{song_name}_stft_{init_ntd}_{subdivision}\"\n",
    "core_beta2, factors_beta2 = scr.NTD_decomp_as_script(paths.path_data_persisted_come_together, persisted_arguments, tensor_mag, ntd_dimensions, init = init_ntd, update_rule = \"hals\", beta = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:19:34.458541Z",
     "start_time": "2022-08-01T11:16:12.242183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Griffin-Lim\n",
      "SDR at the songscale: -38.46780219111554\n",
      "SDR at the patternscale: avg = -20.814493857782285, std = 2.437747072404799\n",
      "The current masked spectrogram is too close to the ogirinal spectrogram, the SDR would be disinformative.\n",
      "The current masked spectrogram is too close to the ogirinal spectrogram, the SDR would be disinformative.\n",
      "Masking\n",
      "SDR at the songscale: 4.350775455906698\n",
      "SDR at the patternscale: avg = 16.70731643232073, std = 5.101187884719196\n"
     ]
    }
   ],
   "source": [
    "# Patterns Griffin-Lim\n",
    "song_sdr_gl, patterns_sdr_gl, audio_song_ntd_gl, audio_patterns_ntd_gl = ps.sdr_songscale_patternscale_encpasulation(core_beta2, factors_beta2, median_hop, \n",
    "                                         tensor_mag_original = tensor_mag, tensor_phase_original = tensor_phase,\n",
    "                                         phase_retrieval_song = \"griffin_lim\", phase_retrieval_patterns = \"griffin_lim\")\n",
    "print(\"Griffin-Lim\")\n",
    "\n",
    "print(f\"SDR at the songscale: {song_sdr_gl}\")\n",
    "print(f\"SDR at the patternscale: avg = {np.mean(patterns_sdr_gl)}, std = {np.std(patterns_sdr_gl)}\")\n",
    "\n",
    "if listen_audio:\n",
    "    ipd.display(audio_song_ntd_gl)\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        ipd.display(audio_patterns_ntd_gl[i])\n",
    "\n",
    "if plot_patterns:\n",
    "    spec_patterns_ntd = ps.compute_patterns(core, factors[0], factors[1])\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        plot_me_this_spectrogram(spec_patterns_ntd[i], title = f\"{i}-th pattern\")\n",
    "        \n",
    "# Patterns softmasking\n",
    "song_sdr_mask, patterns_sdr_mask, audio_song_ntd_mask, audio_patterns_ntd_mask = ps.sdr_songscale_patternscale_encpasulation(core_beta2, factors_beta2, median_hop, \n",
    "                                         tensor_mag_original = tensor_mag, tensor_phase_original = tensor_phase,\n",
    "                                         phase_retrieval_song = \"original_phase\", phase_retrieval_patterns = \"softmasking\")\n",
    "print(\"Softmasking\")\n",
    "print(f\"SDR at the songscale: {song_sdr_mask}\")\n",
    "print(f\"SDR at the patternscale: avg = {np.mean(patterns_sdr_mask)}, std = {np.std(patterns_sdr_mask)}\")\n",
    "\n",
    "if listen_audio:\n",
    "    ipd.display(audio_song_ntd_mask)\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        ipd.display(audio_patterns_ntd_mask[i])\n",
    "        \n",
    "if plot_patterns:\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        plot_me_this_spectrogram(spec_patterns_ntd[i], title = f\"{i}-th pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:19:34.474533Z",
     "start_time": "2022-08-01T11:19:34.462530Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "persisted_arguments = f\"mu_slow_{song_name}_beta1_stft_{init_ntd}_{subdivision}_n_iter_max1000\"\n",
    "core_beta1, factors_beta1 = scr.NTD_decomp_as_script(paths.path_data_persisted_come_together, persisted_arguments, tensor_mag, ntd_dimensions, init = init_ntd, update_rule = \"mu\", beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:22:55.708587Z",
     "start_time": "2022-08-01T11:19:34.477489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Griffin-Lim\n",
      "SDR at the songscale: -34.52657827635712\n",
      "SDR at the patternscale: avg = -17.68561909189689, std = 3.0296033687002533\n",
      "Masking\n",
      "SDR at the songscale: 6.077240279730299\n",
      "SDR at the patternscale: avg = 25.942390346762654, std = 5.481567223668133\n"
     ]
    }
   ],
   "source": [
    "# Patterns Griffin-Lim\n",
    "song_sdr_gl, patterns_sdr_gl, audio_song_ntd_gl, audio_patterns_ntd_gl = ps.sdr_songscale_patternscale_encpasulation(core_beta1, factors_beta1, median_hop, \n",
    "                                         tensor_mag_original = tensor_mag, tensor_phase_original = tensor_phase,\n",
    "                                         phase_retrieval_song = \"griffin_lim\", phase_retrieval_patterns = \"griffin_lim\")\n",
    "print(\"Griffin-Lim\")\n",
    "print(f\"SDR at the songscale: {song_sdr_gl}\")\n",
    "print(f\"SDR at the patternscale: avg = {np.mean(patterns_sdr_gl)}, std = {np.std(patterns_sdr_gl)}\")\n",
    "\n",
    "if listen_audio:\n",
    "    ipd.display(audio_song_ntd_gl)\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        ipd.display(audio_patterns_ntd_gl[i])\n",
    "\n",
    "if plot_patterns:\n",
    "    spec_patterns_ntd = ps.compute_patterns(core, factors[0], factors[1])\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        plot_me_this_spectrogram(spec_patterns_ntd[i], title = f\"{i}-th pattern\")\n",
    "\n",
    "# Patterns softmasking\n",
    "song_sdr_mask, patterns_sdr_mask, audio_song_ntd_mask, audio_patterns_ntd_mask = ps.sdr_songscale_patternscale_encpasulation(core_beta1, factors_beta1, median_hop, \n",
    "                                         tensor_mag_original = tensor_mag, tensor_phase_original = tensor_phase,\n",
    "                                         phase_retrieval_song = \"original_phase\", phase_retrieval_patterns = \"softmasking\")\n",
    "print(\"Softmasking\")\n",
    "print(f\"SDR at the songscale: {song_sdr_mask}\")\n",
    "print(f\"SDR at the patternscale: avg = {np.mean(patterns_sdr_mask)}, std = {np.std(patterns_sdr_mask)}\")\n",
    "\n",
    "if listen_audio:\n",
    "    ipd.display(audio_song_ntd_mask)\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        ipd.display(audio_patterns_ntd_mask[i])\n",
    "        \n",
    "if plot_patterns:\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        plot_me_this_spectrogram(spec_patterns_ntd[i], title = f\"{i}-th pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BETA 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:22:55.739504Z",
     "start_time": "2022-08-01T11:22:55.711602Z"
    }
   },
   "outputs": [],
   "source": [
    "persisted_arguments = f\"mu_slow_{song_name}_beta0_stft_{init_ntd}_{subdivision}_n_iter_max1000\"\n",
    "core_beta0, factors_beta0 = scr.NTD_decomp_as_script(paths.path_data_persisted_come_together, persisted_arguments, tensor_mag, ntd_dimensions, init = init_ntd, update_rule = \"mu\", beta = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-01T11:25:52.988983Z",
     "start_time": "2022-08-01T11:22:55.746485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Griffin-Lim\n",
      "SDR at the songscale: -36.990796615261424\n",
      "SDR at the patternscale: avg = -20.47174234998537, std = 3.478175207131415\n",
      "The current masked spectrogram is too close to the ogirinal spectrogram, the SDR would be disinformative.\n",
      "Masking\n",
      "SDR at the songscale: 2.511286202438921\n",
      "SDR at the patternscale: avg = 19.01875056777578, std = 8.705962166649469\n"
     ]
    }
   ],
   "source": [
    "# Patterns Griffin-Lim\n",
    "song_sdr_gl, patterns_sdr_gl, audio_song_ntd_gl, audio_patterns_ntd_gl = ps.sdr_songscale_patternscale_encpasulation(core_beta0, factors_beta0, median_hop, \n",
    "                                         tensor_mag_original = tensor_mag, tensor_phase_original = tensor_phase,\n",
    "                                         phase_retrieval_song = \"griffin_lim\", phase_retrieval_patterns = \"griffin_lim\")\n",
    "print(\"Griffin-Lim\")\n",
    "print(f\"SDR at the songscale: {song_sdr_gl}\")\n",
    "print(f\"SDR at the patternscale: avg = {np.mean(patterns_sdr_gl)}, std = {np.std(patterns_sdr_gl)}\")\n",
    "\n",
    "if listen_audio:\n",
    "    ipd.display(audio_song_ntd_gl)\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        ipd.display(audio_patterns_ntd_gl[i])\n",
    "\n",
    "if plot_patterns:    \n",
    "    spec_patterns_ntd = ps.compute_patterns(core, factors[0], factors[1])\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        plot_me_this_spectrogram(spec_patterns_ntd[i], title = f\"{i}-th pattern\")\n",
    "\n",
    "# Patterns softmasking\n",
    "song_sdr_mask, patterns_sdr_mask, audio_song_ntd_mask, audio_patterns_ntd_mask = ps.sdr_songscale_patternscale_encpasulation(core_beta0, factors_beta0, median_hop, \n",
    "                                         tensor_mag_original = tensor_mag, tensor_phase_original = tensor_phase,\n",
    "                                         phase_retrieval_song = \"original_phase\", phase_retrieval_patterns = \"softmasking\")\n",
    "print(\"Softmasking\")\n",
    "print(f\"SDR at the songscale: {song_sdr_mask}\")\n",
    "print(f\"SDR at the patternscale: avg = {np.mean(patterns_sdr_mask)}, std = {np.std(patterns_sdr_mask)}\")\n",
    "\n",
    "if listen_audio:\n",
    "    ipd.display(audio_song_ntd_mask)\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        ipd.display(audio_patterns_ntd_mask[i])\n",
    "        \n",
    "if plot_patterns:\n",
    "    for i in range(nb_patterns_to_show):\n",
    "        plot_me_this_spectrogram(spec_patterns_ntd[i], title = f\"{i}-th pattern\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
