{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:02:43.336379Z",
     "start_time": "2022-07-21T19:02:37.968205Z"
    }
   },
   "outputs": [],
   "source": [
    "import barmuscomp.ae_utils as ae_utils\n",
    "import barmuscomp.ae as ae\n",
    "import barmuscomp.ae_ntd as ae_ntd\n",
    "import barmuscomp.scripts.default_path as paths\n",
    "import barmuscomp.scripts.overall_scripts as scr\n",
    "import barmuscomp.model.features as features\n",
    "from barmuscomp.model.current_plot import *\n",
    "\n",
    "import as_seg.CBM_algorithm as CBM\n",
    "import as_seg.barwise_input as bi\n",
    "import as_seg.data_manipulation as dm\n",
    "import as_seg.autosimilarity_computation as as_comp\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mirdata\n",
    "import os\n",
    "import tensorly as tl\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:02:43.383213Z",
     "start_time": "2022-07-21T19:02:43.369251Z"
    }
   },
   "outputs": [],
   "source": [
    "## Important parameters\n",
    "feature = \"nn_log_mel_grill\"\n",
    "beta = 1\n",
    "ntd_dimensions = [24,24,24]\n",
    "plot_patterns = True\n",
    "nb_patterns = 4\n",
    "autosimilarity_type = \"Cosine\"\n",
    "compute_if_not_persisted = False\n",
    "verbose = False\n",
    "latent_nonlinearity = \"softmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:02:44.734858Z",
     "start_time": "2022-07-21T19:02:43.415128Z"
    }
   },
   "outputs": [],
   "source": [
    "subdivision = 96\n",
    "hop_length = 32\n",
    "hop_length_seconds = hop_length/44100\n",
    "\n",
    "song_name = \"The Beatles - Come Together\"\n",
    "spectrogram, bars, references_segments = scr.load_spec_annot_cometogether(feature, hop_length)\n",
    "#song_name = 1\n",
    "#spectrogram, bars, references_segments = scr.load_spec_annot_song_RWC(song_name, feature, hop_length)\n",
    "\n",
    "batch_size = None\n",
    "lr = 1e-3\n",
    "n_epochs = 1000\n",
    "\n",
    "tensor_spectrogram = bi.tensorize_barwise_BFT(spectrogram, bars, hop_length_seconds, subdivision)\n",
    "fc_data_loader = ae_utils.generate_flatten_dataloader(tensor_spectrogram, batch_size = batch_size)\n",
    "conv_data_loader = ae_utils.generate_dataloader(tensor_spectrogram, batch_size = batch_size)\n",
    "\n",
    "freq_size = tensor_spectrogram.shape[1]\n",
    "\n",
    "tensor_spectrogram_ntd = bi.tensorize_barwise_FTB(spectrogram, bars, hop_length_seconds, subdivision)\n",
    "\n",
    "init_ntd = \"tucker\"\n",
    "if beta == 2:\n",
    "    persisted_arguments = f\"_{song_name}_{feature}_{init_ntd}_{subdivision}\"\n",
    "    core, factors = scr.NTD_decomp_as_script(paths.path_data_persisted_come_together, persisted_arguments, tensor_spectrogram_ntd, ntd_dimensions, init = init_ntd, update_rule = \"hals\", beta = 2, compute_if_not_persisted = compute_if_not_persisted)\n",
    "else:\n",
    "    persisted_arguments = f\"mu_slow_{song_name}_beta{beta}_{feature}_{init_ntd}_{subdivision}_n_iter_max1000\"\n",
    "    core, factors = scr.NTD_decomp_as_script(paths.path_data_persisted_come_together, persisted_arguments, tensor_spectrogram_ntd, ntd_dimensions, init = init_ntd, update_rule = \"mu\", beta = beta, compute_if_not_persisted = compute_if_not_persisted)\n",
    "bn_latent_init_stds = [np.std(factors[2][:,i]) for i in range(factors[2].shape[1])]\n",
    "bn_latent_init_avgs = [np.mean(factors[2][:,i]) for i in range(factors[2].shape[1])]\n",
    "\n",
    "if beta == 2:\n",
    "    recons_loss = torch.nn.MSELoss()\n",
    "else:\n",
    "    recons_loss = ae_utils.BetaDivergenceLoss(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:02:50.871644Z",
     "start_time": "2022-07-21T19:02:50.840697Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_projection_score(projection, autosimilarity_type = autosimilarity_type, convolution_type = \"14_bands\"):\n",
    "    projection = np.array(projection)\n",
    "    projection = np.where(abs(projection) < 1e-15, 0, projection)\n",
    "    \n",
    "    autosimilarity = as_comp.switch_autosimilarity(projection, similarity_type = autosimilarity_type, normalise = True)\n",
    "    segments = CBM.compute_cbm(autosimilarity, penalty_weight = 1, penalty_func = \"modulo8\", convolution_type = convolution_type)[0]                \n",
    "    segments_in_time = dm.segments_from_bar_to_time(segments, bars)\n",
    "\n",
    "    f_mes_zero_five = dm.compute_score_of_segmentation(references_segments, segments_in_time, window_length = 0.5)[2]\n",
    "    f_mes_three = dm.compute_score_of_segmentation(references_segments, segments_in_time, window_length = 3)[2]\n",
    "    \n",
    "    print(f\"Score at 0.5s: {f_mes_zero_five}, score at 3s: {f_mes_three}\")\n",
    "    \n",
    "def plot_audio_diff_ntd_ae_in_dataframe(signal_ntd, signal_ae):\n",
    "    df = pd.DataFrame(np.array([signal_ntd, signal_ae]), index = [\"Audio NTD\", \"Audio AE\"])\n",
    "    for i in range(df.shape[1]):\n",
    "        df[i] = df[i].T.apply(lambda x:x._repr_html_().replace('\\n', '').strip())#, axis=1)\n",
    "    df_html = df.T.to_html(escape=False, index=False)\n",
    "    ipd.display(ipd.HTML(df_html))\n",
    "    \n",
    "def plot_spec_ntd_ae(spec_1, spec_2, title, to_permute = True, plot_diff = False):\n",
    "    if spec_1.shape[0] == spec_1.shape[1]:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(14,7))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15,min(5, 15*spec_1.shape[0]/spec_1.shape[1])))\n",
    "    if to_permute:\n",
    "        permut_1 = permutate_factor(spec_1.T) \n",
    "        spec_1 = spec_1[permut_1]\n",
    "        permut_2 = permutate_factor(spec_2.T)\n",
    "        spec_2 = spec_2[permut_2]\n",
    "    diff = spec_2 - spec_1\n",
    "    axs[0].pcolormesh(np.arange(spec_1.shape[1]), np.arange(spec_1.shape[0]), spec_1, cmap=cm.Greys, shading='auto')\n",
    "    axs[0].set_title(f\"{title} of NTD\")\n",
    "    axs[1].pcolormesh(np.arange(spec_2.shape[1]), np.arange(spec_2.shape[0]), spec_2, cmap=cm.Greys, shading='auto')\n",
    "    axs[1].set_title(f\"{title} of AE\")\n",
    "    axs[0].invert_yaxis()\n",
    "    axs[1].invert_yaxis()\n",
    "    plt.show()\n",
    "    if plot_diff:\n",
    "        if spec_1.shape[0] == spec_1.shape[1]:\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(14,7))\n",
    "        else:\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(15,min(5, 15*spec_1.shape[0]/spec_1.shape[1])))\n",
    "        axs[0].pcolormesh(np.arange(diff.shape[1]), np.arange(diff.shape[0]), diff, cmap=cm.Greys, shading='auto')\n",
    "        axs[0].set_title(f\"Diff entre les 2 spectrogrammes\\n (couleurs normalisées entre min et max)\\n Diff maximale: {np.amax(np.abs(diff))}\")\n",
    "        the_max = max(np.amax(spec_1), np.amax(spec_2))\n",
    "        axs[1].pcolormesh(np.arange(diff.shape[1]), np.arange(diff.shape[0]), diff, cmap=cm.Greys, vmin=0, vmax=the_max, shading='auto')\n",
    "        axs[1].set_title(f\"Diff entre les 2 spectrogrammes\\n (couleurs normalisées entre 0 et max des 2 spectrogrammes)\\n Valeur max des 2 specs{the_max}\")\n",
    "        axs[0].invert_yaxis()\n",
    "        axs[1].invert_yaxis()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:02:52.296714Z",
     "start_time": "2022-07-21T19:02:52.277764Z"
    }
   },
   "outputs": [],
   "source": [
    "hops = []\n",
    "for bar_idx in range(tensor_spectrogram_ntd.shape[2]):\n",
    "    len_sig = bars[bar_idx+1][1] - bars[bar_idx+1][0]\n",
    "    hop = int(len_sig/96 * 44100)\n",
    "    hops.append(hop)\n",
    "median_hop = int(np.median(hops)) #For audio reconstruction\n",
    "\n",
    "def plot_patterns_ae_and_ntd(spec_patterns_ntd, patterns_ntd, core_ae, factors_ae, nb_patterns = nb_patterns):\n",
    "    for i in range(nb_patterns):\n",
    "        pattern = factors_ae[0]@core_ae[:,:,i]@factors_ae[1].T\n",
    "        plot_spec_ntd_ae(spec_patterns_ntd[i], pattern, title = f\"{i}-th pattern in the decoder\", to_permute = False)\n",
    "        audio = features.get_audio_from_spectrogram(pattern, feature, hop_length = median_hop, sr = 44100)\n",
    "        plot_audio_diff_ntd_ae_in_dataframe(patterns_ntd[i], audio)\n",
    "        \n",
    "def plot_comparison_this_ae_ntd(ssae, projection):\n",
    "    autosimil = as_comp.switch_autosimilarity(projection, similarity_type = autosimilarity_type, normalise = True)\n",
    "    plot_spec_ntd_ae(autosimilarity_ntd, autosimil, \"Autosimilarity\", to_permute = False)\n",
    "    get_projection_score(projection)\n",
    "\n",
    "    W = ssae.get_W()\n",
    "    H = ssae.get_H()\n",
    "    proj_np = np.array(projection).T\n",
    "\n",
    "    plot_spec_ntd_ae(factors[0], W, title = \"W matrix\")\n",
    "    plot_spec_ntd_ae(factors[1].T, H.T, title = \"H matrix\")\n",
    "    plot_spec_ntd_ae(factors[2].T, proj_np, title = \"Latent representations\")\n",
    "    if plot_patterns:\n",
    "        G = ssae.get_G()\n",
    "        plot_patterns_ae_and_ntd(spec_patterns_ntd, patterns_ntd, G, [W, H])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultats NTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:03:02.518339Z",
     "start_time": "2022-07-21T19:02:53.745880Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recons = tl.tenalg.multi_mode_dot(core, factors)\n",
    "\n",
    "autosimilarity_ntd = as_comp.switch_autosimilarity(factors[2], similarity_type = autosimilarity_type, normalise = True)\n",
    "plot_me_this_spectrogram(autosimilarity_ntd, title = \"Autosimilarity of Q\")\n",
    "get_projection_score(factors[2])\n",
    "print(f\"NTD reconstruction error: {recons_loss(torch.tensor(tensor_spectrogram_ntd).float(), torch.tensor(recons).float())}\")\n",
    "\n",
    "plot_me_this_spectrogram(factors[0], title = \"W matrix\")\n",
    "plot_me_this_spectrogram(factors[1].T, title = \"H matrix\")\n",
    "plot_me_this_spectrogram(factors[2].T, title = \"Q matrix\")\n",
    "if plot_patterns:\n",
    "    patterns_ntd = []\n",
    "    spec_patterns_ntd = []\n",
    "    for i in range(nb_patterns):\n",
    "        pattern = factors[0]@core[:,:,i]@factors[1].T\n",
    "        spec_patterns_ntd.append(pattern)\n",
    "        plot_me_this_spectrogram(pattern, title = f\"{i}-th pattern\")\n",
    "        audio = features.get_audio_from_spectrogram(pattern, feature, hop_length = median_hop, sr = 44100)\n",
    "        patterns_ntd.append(audio)\n",
    "        ipd.display(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Décodeur Aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:20:13.078380Z",
     "start_time": "2022-07-21T16:12:19.447798Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fc_random_decoder = ae_ntd.FullyConnectedAutoencoderNTD(input_size_x = subdivision, input_size_y = freq_size, \n",
    "                                                        ntd_dimensions = ntd_dimensions, unfolded_G = None, W = None, H = None,\n",
    "                                                        bn_latent_init_stds = None, bn_latent_init_avgs = None,\n",
    "                                                        beta = beta, seed = 42, latent_nonlinearity = latent_nonlinearity)\n",
    "fc_random_decoder, losses = fc_random_decoder.my_optim_method(n_epochs, fc_data_loader, verbose = verbose, lr = lr)\n",
    "print(f\"Final reconstruction error: {losses[-1]}\")\n",
    "plt.plot(losses)\n",
    "plt.title(\"Reconstruction error with iterations\")\n",
    "plt.legend([\"Reconstruction error\"])\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "projection_fc_random = fc_random_decoder.get_latent_projection(fc_data_loader)\n",
    "plot_comparison_this_ae_ntd(fc_random_decoder, projection_fc_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Décodeur avec W et H \"apprises\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:03:02.661953Z",
     "start_time": "2022-07-21T19:03:02.648987Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "path_to_save_cluster = \"C:/Users/amarmore/Desktop/data_persisted/cluster_matrices\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W et H apprises -> clustering de toutes les colonnes des NTD réalisées avec ces rangs sur RWC Pop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices contenant toutes les colonnes de W (resp. H) pour les chansons de RWC Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:03:03.049148Z",
     "start_time": "2022-07-21T19:03:02.774653Z"
    }
   },
   "outputs": [],
   "source": [
    "big_h = []\n",
    "big_w = []\n",
    "for song_name in range(1,101):\n",
    "    if beta == 2:\n",
    "        persisted_arguments = f\"_{song_name}_{feature}_{init_ntd}_{subdivision}\"\n",
    "        _, factors_tmp = scr.NTD_decomp_as_script(paths.path_data_persisted_rwc, persisted_arguments, None, ntd_dimensions, init = init_ntd, update_rule = \"hals\", beta = 2, compute_if_not_persisted = False)\n",
    "    else:\n",
    "        persisted_arguments = f\"mu_slow_{song_name}_beta{beta}_{feature}_{init_ntd}_{subdivision}_n_iter_max1000\"\n",
    "        _, factors_tmp = scr.NTD_decomp_as_script(paths.path_data_persisted_rwc, persisted_arguments, None, ntd_dimensions, init = init_ntd, update_rule = \"mu\", beta = beta, compute_if_not_persisted = False)\n",
    "    \n",
    "    for column_h in factors_tmp[1].T:\n",
    "        big_h.append(column_h)\n",
    "    for column_w in factors_tmp[0].T:\n",
    "        big_w.append(column_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centre des clusters pour H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:03:29.810782Z",
     "start_time": "2022-07-21T19:03:28.618981Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeansh = sklearn.cluster.KMeans(n_clusters = ntd_dimensions[1], random_state = 42).fit(big_h)\n",
    "k_means_h = kmeansh.cluster_centers_\n",
    "k_means_h = k_means_h.T\n",
    "np.save(f\"{path_to_save_cluster}/kmeans_H_rwcpop_dimensions{ntd_dimensions}_beta{beta}\", k_means_h)\n",
    "#k_means_h = np.load(f\"{path_to_save_cluster}/kmeans_H_rwcpop_dimensions{ntd_dimensions}_beta{beta}.npy\")\n",
    "perm_cluster_h = permutate_factor(k_means_h)\n",
    "plot_me_this_spectrogram(k_means_h[:,perm_cluster_h].T, title = \"Cluster centroids for H\", x_axis = \"Bar index\", y_axis = \"Rhythmic patterns\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Centre des clusters pour W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T19:03:17.193631Z",
     "start_time": "2022-07-21T19:03:16.027357Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeansw = sklearn.cluster.KMeans(n_clusters = ntd_dimensions[0], random_state = 42).fit(big_w)\n",
    "k_means_w = kmeansw.cluster_centers_\n",
    "k_means_w = k_means_w.T\n",
    "np.save(f\"{path_to_save_cluster}/kmeans_W_rwcpop_dimensions{ntd_dimensions}_beta{beta}\", k_means_w)\n",
    "#k_means_w = np.load(f\"{path_to_save_cluster}/kmeans_W_rwcpop_dimensions{ntd_dimensions}_beta{beta}.npy\")\n",
    "perm_cluster_w = permutate_factor(k_means_w)\n",
    "plot_me_this_spectrogram(k_means_w[:,perm_cluster_w], title = \"Cluster centroids for W\", x_axis = \"Bar index\", y_axis = \"Spectral patterns\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:27:48.769724Z",
     "start_time": "2022-07-21T16:20:14.323047Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fc_init_centroid = ae_ntd.FullyConnectedAutoencoderNTD(input_size_x = subdivision, input_size_y = freq_size, \n",
    "                                                        ntd_dimensions = ntd_dimensions, unfolded_G = None, W = k_means_w, H = k_means_h,\n",
    "                                                        bn_latent_init_stds = None, bn_latent_init_avgs = None,\n",
    "                                                        beta = beta, seed = 42, latent_nonlinearity = latent_nonlinearity)\n",
    "fc_init_centroid, losses = fc_init_centroid.my_optim_method(n_epochs, fc_data_loader, verbose = verbose, lr = lr)\n",
    "print(f\"Final reconstruction error: {losses[-1]}\")\n",
    "plt.plot(losses)\n",
    "plt.title(\"Reconstruction error with iterations\")\n",
    "plt.legend([\"Reconstruction error\"])\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "projection_fc_init_centroid = fc_init_centroid.get_latent_projection(fc_data_loader)\n",
    "plot_comparison_this_ae_ntd(fc_init_centroid, projection_fc_init_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Décodeur initalisé avec NTD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-21T16:33:48.498232Z",
     "start_time": "2022-07-21T16:27:48.773707Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fc_init_ntd = ae_ntd.FullyConnectedAutoencoderNTD(input_size_x = subdivision, input_size_y = freq_size, \n",
    "                                                        ntd_dimensions = ntd_dimensions, unfolded_G = tl.unfold(core, 2),\n",
    "                                                        W = factors[0], H = factors[1],\n",
    "                                                        bn_latent_init_stds = bn_latent_init_stds, bn_latent_init_avgs = bn_latent_init_avgs,\n",
    "                                                        beta = beta, seed = 42, latent_nonlinearity = latent_nonlinearity)\n",
    "fc_init_ntd, losses = fc_init_ntd.my_optim_method(n_epochs, fc_data_loader, verbose = verbose, lr = lr)\n",
    "print(f\"Final reconstruction error: {losses[-1]}\")\n",
    "plt.plot(losses)\n",
    "plt.title(\"Reconstruction error with iterations\")\n",
    "plt.legend([\"Reconstruction error\"])\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "projection_fc_init_ntd = fc_init_ntd.get_latent_projection(fc_data_loader)\n",
    "plot_comparison_this_ae_ntd(fc_init_ntd, projection_fc_init_ntd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
